{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# InfoGenAI User Interface\n",
        "This Jupyter Notebook implements a web user interface to InfoGenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install gradio requests --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Running on local URL:  http://127.0.0.1:7862\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\Mika\\miniconda3\\envs\\mwtuni\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\Mika\\miniconda3\\envs\\mwtuni\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\Mika\\miniconda3\\envs\\mwtuni\\Lib\\site-packages\\gradio\\blocks.py\", line 2136, in process_api\n",
            "    result = await self.call_function(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\Mika\\miniconda3\\envs\\mwtuni\\Lib\\site-packages\\gradio\\blocks.py\", line 1662, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\Mika\\miniconda3\\envs\\mwtuni\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
            "    return await get_async_backend().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\Mika\\miniconda3\\envs\\mwtuni\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\Mika\\miniconda3\\envs\\mwtuni\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 967, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\Mika\\miniconda3\\envs\\mwtuni\\Lib\\site-packages\\gradio\\utils.py\", line 884, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\Mika\\AppData\\Local\\Temp\\ipykernel_26584\\2817088996.py\", line 110, in update_agents\n",
            "    agents, updated_debug = fetch_agents(backend_url, debug_messages)\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "TypeError: fetch_agents() missing 1 required positional argument: 'debug_messages'\n"
          ]
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import requests\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "# JavaScript function to enforce the dark theme\n",
        "js_func = \"\"\"\n",
        "function refresh() {\n",
        "    const url = new URL(window.location);\n",
        "\n",
        "    if (url.searchParams.get('__theme') !== 'dark') {\n",
        "        url.searchParams.set('__theme', 'dark');\n",
        "        window.location.href = url.href;\n",
        "    }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "def append_debug_message(debug_messages, message):\n",
        "    \"\"\"Appends a timestamped debug message to the debug log.\"\"\"\n",
        "    from datetime import datetime\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S.%f\")[:-3]\n",
        "    debug_messages.append(f\"{timestamp} D {message}\")\n",
        "    return debug_messages\n",
        "\n",
        "def fetch_agents(backend_url, session_id, debug_messages):\n",
        "    \"\"\"Fetches the list of agents from the backend and logs the communication.\"\"\"\n",
        "    try:\n",
        "        debug_messages = append_debug_message(debug_messages, f\"Sending request to fetch agents: {backend_url}\")\n",
        "        response = requests.post(backend_url, data={\"Body\": \"list_agents\", \"SessionID\": session_id})\n",
        "        if response.status_code == 200:\n",
        "            response_data = response.json()\n",
        "            session_id = response_data.get(\"SessionID\", session_id)  # Update session ID\n",
        "            agents_text = response_data.get(\"Response\", \"\")\n",
        "            agent_descriptions = [line for line in agents_text.split(\"\\n\") if \" - \" in line]\n",
        "            agent_names = [line.split(\" - \")[0] for line in agent_descriptions]\n",
        "            debug_messages = append_debug_message(debug_messages, f\"Received agents: {agent_names}\")\n",
        "            return agent_names, session_id, debug_messages\n",
        "        else:\n",
        "            error_message = f\"Error: Unable to fetch agents. Status code: {response.status_code}\"\n",
        "            debug_messages = append_debug_message(debug_messages, error_message)\n",
        "            return [error_message], session_id, debug_messages\n",
        "    except requests.RequestException as e:\n",
        "        error_message = f\"Request failed: {e}\"\n",
        "        debug_messages = append_debug_message(debug_messages, error_message)\n",
        "        return [error_message], session_id, debug_messages\n",
        "\n",
        "def analyze(prompt, backend_url, selected_agents, session_id, debug_messages):\n",
        "    \"\"\"\n",
        "    Sends the article or URL to the backend for analysis and logs the communication.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Check if the input is a URL\n",
        "        from urllib.parse import urlparse\n",
        "        parsed_url = urlparse(prompt)\n",
        "        if parsed_url.scheme in [\"http\", \"https\"]:\n",
        "            debug_messages = append_debug_message(debug_messages, f\"Fetching article content from URL: {prompt}\")\n",
        "            try:\n",
        "                # Fetch the content of the URL\n",
        "                response = requests.get(prompt)\n",
        "                response.raise_for_status()  # Raise an error for HTTP errors\n",
        "                prompt = response.text  # Use the fetched content as the article text\n",
        "                debug_messages = append_debug_message(debug_messages, \"Successfully fetched article content.\")\n",
        "            except requests.RequestException as e:\n",
        "                error_message = f\"Error fetching article content: {e}\"\n",
        "                debug_messages = append_debug_message(debug_messages, error_message)\n",
        "                return error_message, session_id, debug_messages\n",
        "\n",
        "        # Process the article with the backend\n",
        "        selected_agents = [agent.split(\" - \")[0] for agent in selected_agents if agent]\n",
        "        debug_messages = append_debug_message(debug_messages, f\"Sending analysis request with agents: {selected_agents}\")\n",
        "        response = requests.post(\n",
        "            backend_url,\n",
        "            data={\"Body\": prompt, \"Agents\": \",\".join(selected_agents), \"SessionID\": session_id},\n",
        "        )\n",
        "        if response.status_code == 200:\n",
        "            response_data = response.json()\n",
        "            session_id = response_data.get(\"SessionID\", session_id)  # Update session ID\n",
        "            response_text = response_data.get(\"Response\", \"\")\n",
        "            debug_messages = append_debug_message(debug_messages, f\"Received analysis response: {response_text}\")\n",
        "            return response_text, session_id, debug_messages\n",
        "        else:\n",
        "            error_message = f\"Error: {response.status_code} - {response.text}\"\n",
        "            debug_messages = append_debug_message(debug_messages, error_message)\n",
        "            return error_message, session_id, debug_messages\n",
        "    except requests.RequestException as e:\n",
        "        error_message = f\"Request failed: {e}\"\n",
        "        debug_messages = append_debug_message(debug_messages, error_message)\n",
        "        return error_message, session_id, debug_messages\n",
        "\n",
        "with gr.Blocks(js=js_func) as interface:\n",
        "    debug_messages = gr.State([])  # State to store debug messages\n",
        "    session_id = gr.State(\"\")  # State to store the SessionID\n",
        "\n",
        "    with gr.Tab(\"Article\"):\n",
        "        # Backend Section\n",
        "        with gr.Row():\n",
        "            backend_url = gr.Textbox(label=\"Backend URL\", value=\"http://localhost:5000/infofactagents\", interactive=True)\n",
        "\n",
        "        # Agents Section\n",
        "        with gr.Row():\n",
        "            enabled_agents = gr.CheckboxGroup(label=\"Enable Agents\", choices=[], interactive=True)\n",
        "\n",
        "        # Article Section\n",
        "        with gr.Row():\n",
        "            prompt = gr.Textbox(label=\"Enter news article\", lines=5, interactive=True)\n",
        "\n",
        "        # Analyze Button and Trustworthiness Output\n",
        "        with gr.Row():\n",
        "            send_button = gr.Button(\"Analyze\")\n",
        "        with gr.Row():\n",
        "            output = gr.Textbox(label=\"Trustworthiness Analysis\", lines=10, interactive=False)\n",
        "\n",
        "        def update_agents(backend_url, session_id, debug_messages):\n",
        "            agents, session_id, updated_debug = fetch_agents(backend_url, session_id, debug_messages)\n",
        "            return gr.update(choices=agents), session_id, updated_debug\n",
        "\n",
        "        # Automatically fetch agents when the interface starts\n",
        "        interface.load(\n",
        "            fn=update_agents,\n",
        "            inputs=[backend_url, session_id, debug_messages],\n",
        "            outputs=[enabled_agents, session_id, debug_messages],\n",
        "        )\n",
        "\n",
        "        send_button.click(\n",
        "            fn=analyze,\n",
        "            inputs=[prompt, backend_url, enabled_agents, session_id, debug_messages],\n",
        "            outputs=[output, session_id, debug_messages],\n",
        "        )\n",
        "\n",
        "    with gr.Tab(\"Debug\") as debug_tab:\n",
        "        debug_output = gr.Textbox(label=\"Debug Info\", lines=15, interactive=False)\n",
        "\n",
        "        # Refresh debug info whenever the Debug tab is activated\n",
        "        debug_tab.select(\n",
        "            fn=lambda debug_messages: \"\\n\".join(debug_messages),\n",
        "            inputs=debug_messages,\n",
        "            outputs=debug_output,\n",
        "        )\n",
        "\n",
        "    # Automatically refresh the page to enforce the dark theme\n",
        "    gr.HTML(\"<script>refresh();</script>\")\n",
        "\n",
        "interface.launch()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "sihteeri_gradio.ipynb"
    },
    "kernelspec": {
      "display_name": "mwtuni",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
